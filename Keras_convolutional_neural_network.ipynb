{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequentialuential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 1, 28, 28)\n",
    "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28) # 1 - coor channel as grayscale is used, in other case 3 channels, 28x28 pixels\n",
    "else:\n",
    "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 28, 28, 1)\n",
    "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images /= 255 #transform to number between 0 and 1, normalize\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = keras.utils.to_categorical(mnist_train_labels, 10) #one-hot encoding\n",
    "test_labels = keras.utils.to_categorical(mnist_test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHH6zRDn8Zoly+M0S9b/q/h6cb8T3dQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebe133d240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_sample(num):\n",
    "    print(train_labels[num])\n",
    "    label = train_labels[num].argmax(axis=0)\n",
    "    image = train_images[num].reshape([28, 28])\n",
    "    plt.title('Sample: %d Label %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "\n",
    "display_sample(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                activation='relu',\n",
    "                input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Reduce by taking the max of each 2x2 block\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Dropout to avoid overfitting\n",
    "model.add(Dropout(0.25))\n",
    "# Flatten the results to one dimension to pass into final layer\n",
    "model.add(Flatten())\n",
    "# A hidden layer to learn with\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Another dropout\n",
    "model.add(Dropout(0.5))\n",
    "# Final categorization from 0-9 with softmax\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "223s - loss: 0.1912 - acc: 0.9423 - val_loss: 0.0446 - val_acc: 0.9855\n",
      "Epoch 2/10\n",
      "232s - loss: 0.0814 - acc: 0.9758 - val_loss: 0.0326 - val_acc: 0.9894\n",
      "Epoch 3/10\n",
      "234s - loss: 0.0603 - acc: 0.9818 - val_loss: 0.0298 - val_acc: 0.9899\n",
      "Epoch 4/10\n",
      "242s - loss: 0.0500 - acc: 0.9844 - val_loss: 0.0286 - val_acc: 0.9906\n",
      "Epoch 5/10\n",
      "244s - loss: 0.0405 - acc: 0.9867 - val_loss: 0.0287 - val_acc: 0.9916\n",
      "Epoch 6/10\n",
      "248s - loss: 0.0364 - acc: 0.9886 - val_loss: 0.0314 - val_acc: 0.9907\n",
      "Epoch 7/10\n",
      "248s - loss: 0.0314 - acc: 0.9902 - val_loss: 0.0310 - val_acc: 0.9917\n",
      "Epoch 8/10\n",
      "247s - loss: 0.0304 - acc: 0.9904 - val_loss: 0.0303 - val_acc: 0.9915\n",
      "Epoch 9/10\n",
      "247s - loss: 0.0260 - acc: 0.9917 - val_loss: 0.0301 - val_acc: 0.9926\n",
      "Epoch 10/10\n",
      "243s - loss: 0.0250 - acc: 0.9922 - val_loss: 0.0281 - val_acc: 0.9926\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0280623687506\n",
      "test accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"test loss:\", score[0])\n",
    "print(\"test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
